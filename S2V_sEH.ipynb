{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24d47e7-e870-40f0-af9c-d0a9bcee3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good to go!\n"
     ]
    }
   ],
   "source": [
    "print('good to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bf789c-37e8-41f5-ae39-0965706b268b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepchem\n",
      "  Using cached deepchem-2.8.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from deepchem) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.12)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.11.4)\n",
      "Collecting rdkit (from deepchem)\n",
      "  Using cached rdkit-2024.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2024.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit->deepchem) (10.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->deepchem) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->deepchem) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "Using cached deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached rdkit-2024.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.1 MB)\n",
      "Installing collected packages: rdkit, deepchem\n",
      "Successfully installed deepchem-2.8.0 rdkit-2024.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install deepchem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6526ab81-ede7-435a-b530-ecb0ec99c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "2024-06-25 18:21:07.534750: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/opt/conda/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepchem.models import Smiles2Vec\n",
    "\n",
    "# If you haven't installed DeepChem, install it using:\n",
    "# pip install deepchem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e838af-e6f2-4064-8815-1c9917506048",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_sEH \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msEH_data_balanced.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:279\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    273\u001b[0m         path_or_handle,\n\u001b[1;32m    274\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    278\u001b[0m     )\n\u001b[0;32m--> 279\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    282\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/array.pxi:884\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/table.pxi:4251\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:777\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    775\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[1;32m    776\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[0;32m--> 777\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_table_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[1;32m    780\u001b[0m mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:1131\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[0;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_table_to_blocks\u001b[39m(options, block_table, categories, extension_columns):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# Part of table_to_blockmanager\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Convert an arrow table to Block from the internal pandas API\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     columns \u001b[38;5;241m=\u001b[39m block_table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[0;32m-> 1131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sEH = pd.read_parquet('sEH_data_balanced.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b657054-0b2d-430f-8c54-91777fb39715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3622660, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sEH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690083ea-92bb-4926-a158-d5c6b4189bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ded9dd-3315-4751-a941-1771d0ae1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20% of the dataset\n",
    "df_sEH = df_sEH[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefdd6e-e657-4c2d-9c0f-c54815b8fb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0d246-b6da-4b6f-b51f-c2d256c72c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58589dd-39c7-49cf-a2ec-7139c24a1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import deepchem as dc\n",
    "\n",
    "# Sample Data\n",
    "smiles = df_sEH['molecule_smiles'].tolist()\n",
    "\n",
    "# Define the character to index mapping, ensuring all unique characters in the SMILES strings are included\n",
    "unique_chars = sorted(set(''.join(smiles)))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "char_to_idx['PAD'] = len(char_to_idx)  # Add PAD token\n",
    "char_to_idx['<unk>'] = len(char_to_idx)  # Add unknown token for any out-of-vocabulary characters\n",
    "\n",
    "\n",
    "# Featurizer\n",
    "featurizer = dc.feat.SmilesToSeq(char_to_idx, max_len=256, pad_len=0)  # Adjust max_len to 270\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c90eee5-be16-4735-98d4-50a9fbf559de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 500000 SMILES strings in 492.75 seconds.\n",
      "Encoding speed: 1014.71 SMILES strings per second.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the data using CSVLoader with MATFeaturizer\n",
    "import time\n",
    "# Measure encoding speed\n",
    "start_time = time.time()\n",
    "# Featurize the data\n",
    "X = featurizer.featurize(smiles)\n",
    "end_time = time.time()\n",
    "\n",
    "num_smiles = len(df_sEH)\n",
    "encoding_time = end_time - start_time\n",
    "encoding_speed = num_smiles / encoding_time\n",
    "\n",
    "print(f\"Encoded {num_smiles} SMILES strings in {encoding_time:.2f} seconds.\")\n",
    "print(f\"Encoding speed: {encoding_speed:.2f} SMILES strings per second.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442a2955-4f0a-4e57-a4f1-2339dd4302ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec186d39-3b99-48c8-8f7c-d4863cdb8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_sEH['binds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a1339a-6fbe-4769-a5d6-2ae03314daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepChem dataset\n",
    "dataset = dc.data.NumpyDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e8525e-cb44-49a2-b3d4-0046f6eefe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_dataset, valid_dataset = splitter.train_test_split(dataset, frac_train=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aeb5c6b-0188-4434-a658-ba28668dd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "\n",
    "# Define the model\n",
    "model = dc.models.Smiles2Vec(\n",
    "    char_to_idx=char_to_idx,\n",
    "    n_tasks=1,\n",
    "    max_seq_len=256,\n",
    "    embedding_dim=50,\n",
    "    n_classes=2,\n",
    "    use_bidir=True,\n",
    "    use_conv=True,\n",
    "    filters=192,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    rnn_sizes=[224, 384],\n",
    "    rnn_types=[\"GRU\", \"GRU\"],\n",
    "    mode=\"classification\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "629b4d34-6cb2-4efb-bd8e-c38fb023fafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train ROC-AUC Score: 0.9884304091896503\n",
      "  Valid ROC-AUC Score: 0.9887489563464895\n",
      "Epoch 1/3\n",
      "  Training Loss: 0.11277850151062012\n",
      "  Train ROC-AUC Score: 0.9864487625184153\n",
      "  Valid ROC-AUC Score: 0.9863878019531813\n",
      "Epoch 2/3\n",
      "  Training Loss: 0.12451723098754883\n",
      "  Train ROC-AUC Score: 0.9894107547873652\n",
      "  Valid ROC-AUC Score: 0.9892386508307054\n",
      "Epoch 3/3\n",
      "  Training Loss: 0.10235045433044433\n"
     ]
    }
   ],
   "source": [
    "# Custom training loop with verbosity\n",
    "nb_epoch = 3\n",
    "for epoch in range(nb_epoch):\n",
    "    loss = model.fit(train_dataset, nb_epoch=1)\n",
    "    \n",
    "    # Check class distribution in training and validation datasets\n",
    "    train_labels = train_dataset.y\n",
    "    valid_labels = valid_dataset.y\n",
    "    \n",
    "    if len(set(train_labels)) > 1:\n",
    "        train_score = model.evaluate(train_dataset, [dc.metrics.roc_auc_score])\n",
    "        print(f\"  Train ROC-AUC Score: {train_score['metric-1']}\")\n",
    "    else:\n",
    "        print(f\"  Train ROC-AUC Score: Not defined (only one class present in y_true)\")\n",
    "    \n",
    "    if len(set(valid_labels)) > 1:\n",
    "        valid_score = model.evaluate(valid_dataset, [dc.metrics.roc_auc_score])\n",
    "        print(f\"  Valid ROC-AUC Score: {valid_score['metric-1']}\")\n",
    "    else:\n",
    "        print(f\"  Valid ROC-AUC Score: Not defined (only one class present in y_true)\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{nb_epoch}\")\n",
    "    print(f\"  Training Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048e249-9cdc-417b-963e-e12f697ae1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "580d66fe-a525-4eaa-a65c-a7ba94be0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model\n",
    "save_dir = 'S2V_model_sEH_500k'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Save the model\n",
    "model.save_checkpoint(model_dir=save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4a96a2-10eb-4856-9f7f-31f7cbf8588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your S3 Bucket and file key\n",
    "bucket = 'kaggle-leash-bio'\n",
    "test_parquet_key = 'test.parquet'\n",
    "test_parquet_location = f's3://{bucket}/{test_parquet_key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c25bf4a-d289-43ec-a5ad-5b5427fe4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Parquet file\n",
    "df = pd.read_parquet(test_parquet_location, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "929a59ee-1a16-4c5c-a921-a89501e61013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for molecules binding with the sEH protein\n",
    "df_sEH_test = df[df['protein_name'] == 'sEH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ef8ff-6eea-439a-badb-c27fd53952e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reduce for quick view of the test data\n",
    "# df_sEH_test = df_sEH_test.sample(frac=0.0001, random_state=42)  # 20% random sample\n",
    "# print(f\"New DataFrame size: {df_sEH_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d310b3ab-c470-486c-8cce-14e7ad143911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize the data\n",
    "X_test = featurizer.featurize(df_sEH_test['molecule_smiles'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "799d283d-a421-403c-90f5-91d0d87c4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepChem dataset\n",
    "dataset = dc.data.NumpyDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb3da49a-86cc-4efb-a184-1831765bca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict bindings\n",
    "predictions = model.predict(dataset)\n",
    "\n",
    "# Extract the probability of the positive class (binding)\n",
    "probabilities = predictions[:, 0, 1]  # Assuming the second column corresponds to the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f00ce51-d697-4796-991a-a796b205a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295246832</td>\n",
       "      <td>0.095346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>295246835</td>\n",
       "      <td>0.004284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>295246838</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>295246841</td>\n",
       "      <td>0.016648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>295246844</td>\n",
       "      <td>0.083035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674883</th>\n",
       "      <td>296921713</td>\n",
       "      <td>0.200139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674886</th>\n",
       "      <td>296921716</td>\n",
       "      <td>0.294431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674889</th>\n",
       "      <td>296921719</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674892</th>\n",
       "      <td>296921722</td>\n",
       "      <td>0.014221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674895</th>\n",
       "      <td>296921725</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558142 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     binds\n",
       "2        295246832  0.095346\n",
       "5        295246835  0.004284\n",
       "8        295246838  0.035300\n",
       "11       295246841  0.016648\n",
       "14       295246844  0.083035\n",
       "...            ...       ...\n",
       "1674883  296921713  0.200139\n",
       "1674886  296921716  0.294431\n",
       "1674889  296921719  0.002713\n",
       "1674892  296921722  0.014221\n",
       "1674895  296921725  0.002440\n",
       "\n",
       "[558142 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create resulting DataFrame with 'id' and 'binds' columns\n",
    "result_df = pd.DataFrame({\n",
    "    'id': df_sEH_test['id'],\n",
    "    'binds': probabilities\n",
    "})\n",
    "# Display the resulting DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f20b975-d929-47f4-a6b6-291b44962960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558142"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2da300c-bdaf-42d2-a1a0-d3d94b7497f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming result_df is your DataFrame\n",
    "result_df.to_csv('sEH_S2VEC.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9de77e7-cce8-41ee-a5fe-ac26592071cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_submission.csv created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the prediction CSV files\n",
    "she_predictions = pd.read_csv('sEH_S2VEC.csv')\n",
    "hsa_predictions = pd.read_csv('HSA_S2VEC.csv')\n",
    "brd4_predictions = pd.read_csv('BRD4_S2VEC.csv')\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "all_predictions = pd.concat([she_predictions, hsa_predictions, brd4_predictions])\n",
    "\n",
    "# Sort by the 'id' column\n",
    "all_predictions_sorted = all_predictions.sort_values(by='id')\n",
    "\n",
    "# Save to a new CSV file\n",
    "all_predictions_sorted.to_csv('final_submission_S2VEC.csv', index=False)\n",
    "\n",
    "print(\"final_submission.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa226b8-4eb2-4e56-8a95-ff53e95b7301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
