{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d24d47e7-e870-40f0-af9c-d0a9bcee3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good to go!\n"
     ]
    }
   ],
   "source": [
    "print('good to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bf789c-37e8-41f5-ae39-0965706b268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepchem\n",
      "  Using cached deepchem-2.8.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from deepchem) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.12)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.11.4)\n",
      "Collecting rdkit (from deepchem)\n",
      "  Using cached rdkit-2024.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2024.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit->deepchem) (10.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->deepchem) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->deepchem) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "Using cached deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached rdkit-2024.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.1 MB)\n",
      "Installing collected packages: rdkit, deepchem\n",
      "Successfully installed deepchem-2.8.0 rdkit-2024.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install deepchem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6526ab81-ede7-435a-b530-ecb0ec99c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "2024-06-27 18:45:28.317071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/opt/conda/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepchem.models import Smiles2Vec\n",
    "\n",
    "# If you haven't installed DeepChem, install it using:\n",
    "# pip install deepchem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e838af-e6f2-4064-8815-1c9917506048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_HSA = pd.read_parquet('HSA_data_balanced.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b657054-0b2d-430f-8c54-91777fb39715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042050, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HSA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ad246-94fd-4f8b-9cf0-f40097026876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690083ea-92bb-4926-a158-d5c6b4189bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ded9dd-3315-4751-a941-1771d0ae1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20% of the dataset\n",
    "df_HSA = df_HSA[train_size:train_size + train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefdd6e-e657-4c2d-9c0f-c54815b8fb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0d246-b6da-4b6f-b51f-c2d256c72c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58589dd-39c7-49cf-a2ec-7139c24a1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import deepchem as dc\n",
    "\n",
    "# Sample Data\n",
    "smiles = df_HSA['molecule_smiles'].tolist()\n",
    "\n",
    "# Define the character to index mapping, ensuring all unique characters in the SMILES strings are included\n",
    "unique_chars = sorted(set(''.join(smiles)))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "char_to_idx['PAD'] = len(char_to_idx)  # Add PAD token\n",
    "char_to_idx['<unk>'] = len(char_to_idx)  # Add unknown token for any out-of-vocabulary characters\n",
    "\n",
    "\n",
    "# Featurizer\n",
    "featurizer = dc.feat.SmilesToSeq(char_to_idx, max_len=256, pad_len=0)  # Adjust max_len to 270\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c90eee5-be16-4735-98d4-50a9fbf559de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 500000 SMILES strings in 479.39 seconds.\n",
      "Encoding speed: 1043.00 SMILES strings per second.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the data using CSVLoader with MATFeaturizer\n",
    "import time\n",
    "# Measure encoding speed\n",
    "start_time = time.time()\n",
    "# Featurize the data\n",
    "X = featurizer.featurize(smiles)\n",
    "end_time = time.time()\n",
    "\n",
    "num_smiles = len(df_HSA)\n",
    "encoding_time = end_time - start_time\n",
    "encoding_speed = num_smiles / encoding_time\n",
    "\n",
    "print(f\"Encoded {num_smiles} SMILES strings in {encoding_time:.2f} seconds.\")\n",
    "print(f\"Encoding speed: {encoding_speed:.2f} SMILES strings per second.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442a2955-4f0a-4e57-a4f1-2339dd4302ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 256)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec186d39-3b99-48c8-8f7c-d4863cdb8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_HSA['binds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a1339a-6fbe-4769-a5d6-2ae03314daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepChem dataset\n",
    "dataset = dc.data.NumpyDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e8525e-cb44-49a2-b3d4-0046f6eefe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_dataset, valid_dataset = splitter.train_test_split(dataset, frac_train=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aeb5c6b-0188-4434-a658-ba28668dd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "\n",
    "# Define the model\n",
    "model = dc.models.Smiles2Vec(\n",
    "    char_to_idx=char_to_idx,\n",
    "    n_tasks=1,\n",
    "    max_seq_len=256,\n",
    "    embedding_dim=50,\n",
    "    n_classes=2,\n",
    "    use_bidir=True,\n",
    "    use_conv=True,\n",
    "    filters=192,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    rnn_sizes=[224, 384],\n",
    "    rnn_types=[\"GRU\", \"GRU\"],\n",
    "    mode=\"classification\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388b0522-9753-4174-8ed2-6f4866f82124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from S2V_model_HSA_500k\n"
     ]
    }
   ],
   "source": [
    "# Restore the model from the checkpoint\n",
    "# Directory where the model is saved\n",
    "load_dir = 'S2V_model_HSA_500k'\n",
    "\n",
    "model.restore(model_dir=load_dir)\n",
    "\n",
    "# Confirm model is loaded\n",
    "print(\"Model loaded successfully from\", load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b4d34-6cb2-4efb-bd8e-c38fb023fafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train ROC-AUC Score: 0.9542806196402513\n",
      "  Train ROC-AUC Score: 0.9559479570038578\n",
      "  Valid ROC-AUC Score: 0.9521909364217787\n",
      "Epoch 2/2\n",
      "  Training Loss: 0.21360115051269532\n"
     ]
    }
   ],
   "source": [
    "# Custom training loop with verbosity\n",
    "nb_epoch = 2\n",
    "for epoch in range(nb_epoch):\n",
    "    loss = model.fit(train_dataset, nb_epoch=1)\n",
    "    \n",
    "    # Check class distribution in training and validation datasets\n",
    "    train_labels = train_dataset.y\n",
    "    valid_labels = valid_dataset.y\n",
    "    \n",
    "    if len(set(train_labels)) > 1:\n",
    "        train_score = model.evaluate(train_dataset, [dc.metrics.roc_auc_score])\n",
    "        print(f\"  Train ROC-AUC Score: {train_score['metric-1']}\")\n",
    "    else:\n",
    "        print(f\"  Train ROC-AUC Score: Not defined (only one class present in y_true)\")\n",
    "    \n",
    "    if len(set(valid_labels)) > 1:\n",
    "        valid_score = model.evaluate(valid_dataset, [dc.metrics.roc_auc_score])\n",
    "        print(f\"  Valid ROC-AUC Score: {valid_score['metric-1']}\")\n",
    "    else:\n",
    "        print(f\"  Valid ROC-AUC Score: Not defined (only one class present in y_true)\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{nb_epoch}\")\n",
    "    print(f\"  Training Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048e249-9cdc-417b-963e-e12f697ae1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d66fe-a525-4eaa-a65c-a7ba94be0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model\n",
    "save_dir = 'S2V_model_HSA_500k_2'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Save the model\n",
    "model.save_checkpoint(model_dir=save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a96a2-10eb-4856-9f7f-31f7cbf8588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your S3 Bucket and file key\n",
    "bucket = 'kaggle-leash-bio'\n",
    "test_parquet_key = 'test.parquet'\n",
    "test_parquet_location = f's3://{bucket}/{test_parquet_key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25bf4a-d289-43ec-a5ad-5b5427fe4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Parquet file\n",
    "df = pd.read_parquet(test_parquet_location, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a59ee-1a16-4c5c-a921-a89501e61013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for molecules binding with the HSA protein\n",
    "df_HSA_test = df[df['protein_name'] == 'HSA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ef8ff-6eea-439a-badb-c27fd53952e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reduce for quick view of the test data\n",
    "# df_HSA_test = df_HSA_test.sample(frac=0.0001, random_state=42)  # 20% random sample\n",
    "# print(f\"New DataFrame size: {df_HSA_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310b3ab-c470-486c-8cce-14e7ad143911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize the data\n",
    "X_test = featurizer.featurize(df_HSA_test['molecule_smiles'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d283d-a421-403c-90f5-91d0d87c4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepChem dataset\n",
    "dataset = dc.data.NumpyDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3da49a-86cc-4efb-a184-1831765bca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict bindings\n",
    "predictions = model.predict(dataset)\n",
    "\n",
    "# Extract the probability of the positive class (binding)\n",
    "probabilities = predictions[:, 0, 1]  # Assuming the second column corresponds to the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00ce51-d697-4796-991a-a796b205a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295246831</td>\n",
       "      <td>0.006606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295246834</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>295246837</td>\n",
       "      <td>0.003047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>295246840</td>\n",
       "      <td>0.043851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>295246843</td>\n",
       "      <td>0.002371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674882</th>\n",
       "      <td>296921712</td>\n",
       "      <td>0.214810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674885</th>\n",
       "      <td>296921715</td>\n",
       "      <td>0.099954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674888</th>\n",
       "      <td>296921718</td>\n",
       "      <td>0.003710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674891</th>\n",
       "      <td>296921721</td>\n",
       "      <td>0.001986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674894</th>\n",
       "      <td>296921724</td>\n",
       "      <td>0.010749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557895 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     binds\n",
       "1        295246831  0.006606\n",
       "4        295246834  0.004945\n",
       "7        295246837  0.003047\n",
       "10       295246840  0.043851\n",
       "13       295246843  0.002371\n",
       "...            ...       ...\n",
       "1674882  296921712  0.214810\n",
       "1674885  296921715  0.099954\n",
       "1674888  296921718  0.003710\n",
       "1674891  296921721  0.001986\n",
       "1674894  296921724  0.010749\n",
       "\n",
       "[557895 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create resulting DataFrame with 'id' and 'binds' columns\n",
    "result_df = pd.DataFrame({\n",
    "    'id': df_HSA_test['id'],\n",
    "    'binds': probabilities\n",
    "})\n",
    "# Display the resulting DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20b975-d929-47f4-a6b6-291b44962960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557895"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da300c-bdaf-42d2-a1a0-d3d94b7497f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming result_df is your DataFrame\n",
    "result_df.to_csv('HSA_S2VEC_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1c303-72a9-4b4d-840f-b2541e1be61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_submission.csv created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the prediction CSV files\n",
    "she_predictions = pd.read_csv('sEH_S2VEC.csv')\n",
    "hsa_predictions = pd.read_csv('HSA_S2VEC_2.csv')\n",
    "HSA_predictions = pd.read_csv('BRD4_S2VEC_2.csv')\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "all_predictions = pd.concat([she_predictions, hsa_predictions, HSA_predictions])\n",
    "\n",
    "# Sort by the 'id' column\n",
    "all_predictions_sorted = all_predictions.sort_values(by='id')\n",
    "\n",
    "# Save to a new CSV file\n",
    "all_predictions_sorted.to_csv('final_submission_S2VEC_2_BRD4_HSA.csv', index=False)\n",
    "\n",
    "print(\"final_submission.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4493e9c7-bf06-4340-b5f8-bff19e36306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_submission.csv created successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"final_submission.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8ef65-344d-45fa-b2ec-ac1a1435cc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
