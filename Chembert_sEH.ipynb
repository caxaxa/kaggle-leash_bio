{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39a386e-b8c1-4616-bef8-3ac5da0a912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in /opt/conda/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from deepchem) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.12)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/conda/lib/python3.10/site-packages (from deepchem) (1.11.4)\n",
      "Requirement already satisfied: rdkit in /opt/conda/lib/python3.10/site-packages (from deepchem) (2023.9.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->deepchem) (2024.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit->deepchem) (9.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->deepchem) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->deepchem) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0.post200)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepchem\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90cd4c68-bc4a-4a16-b318-1fb9601daf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "2024-06-19 06:40:26.629094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/opt/conda/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import deepchem as dc\n",
    "from deepchem.models.torch_models import MATModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d49806-4a8e-4d81-ae79-c25ee5ca14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_data(df):\n",
    "    smiles = df['molecule_smiles'].tolist()\n",
    "    X = featurizer.featurize(smiles)\n",
    "    y = df['binds'].tolist()\n",
    "    dataset = dc.data.NumpyDataset(X, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dfffe-79a8-4655-b728-ac1f32a71887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e61fdef-1abd-40a8-a769-34a74789b224",
   "metadata": {},
   "source": [
    "## Quick Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef608be-e180-4259-b231-e0920bbd3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize SMILES strings using ConvMolFeaturizer for MAT\n",
    "featurizer = dc.feat.MATFeaturizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f506b6-450a-4600-ae36-6c994d13a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_parquet_to_pandas_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    Reads a Parquet file into a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The path to the Parquet file.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The loaded Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2ecacc-d9a8-4b39-b540-141246e999fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sEH = read_parquet_to_pandas_dataframe('df_sEH.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c4e9f4-7144-4ebd-9bfb-96c9e9f42ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame size: (579626, 3)\n"
     ]
    }
   ],
   "source": [
    "# # Assuming df_sEH is your DataFrame\n",
    "df_sEH = df_sEH.sample(frac=0.2, random_state=42)  # 20% random sample\n",
    "\n",
    "print(f\"New DataFrame size: {df_sEH.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a60660-d53c-445f-bb05-48b9d8e5cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "\n",
    "# Suppress RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3eafb4a-8db7-4586-9b2d-23e19984d7cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset_sEH \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sEH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mfeaturize_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeaturize_data\u001b[39m(df):\n\u001b[1;32m      2\u001b[0m     smiles \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmolecule_smiles\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 3\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dc\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mNumpyDataset(X, y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepchem/feat/base_classes.py:312\u001b[0m, in \u001b[0;36mMolecularFeaturizer.featurize\u001b[0;34m(self, datapoints, log_every_n, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    311\u001b[0m         kwargs_per_datapoint[key] \u001b[38;5;241m=\u001b[39m kwargs[key][i]\n\u001b[0;32m--> 312\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_featurize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_per_datapoint\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mol, Chem\u001b[38;5;241m.\u001b[39mrdchem\u001b[38;5;241m.\u001b[39mMol):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepchem/feat/molecule_featurizers/mat_featurizer.py:236\u001b[0m, in \u001b[0;36mMATFeaturizer._featurize\u001b[0;34m(self, datapoint, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMol is being phased out as a parameter, please pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatapoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chem\n\u001b[0;32m--> 236\u001b[0m datapoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_mol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_node_features_matrix(datapoint)\n\u001b[1;32m    239\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mGetAdjacencyMatrix(datapoint)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepchem/feat/molecule_featurizers/mat_featurizer.py:81\u001b[0m, in \u001b[0;36mMATFeaturizer.construct_mol\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m     79\u001b[0m     mol \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mAddHs(mol)\n\u001b[1;32m     80\u001b[0m     AllChem\u001b[38;5;241m.\u001b[39mEmbedMolecule(mol, maxAttempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mAllChem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUFFOptimizeMolecule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     mol \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mRemoveHs(mol)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset_sEH = featurize_data(df_sEH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff69ee-6d68-4027-ae87-735d0e88d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = dc.splits.RandomSplitter()\n",
    "\n",
    "train_dataset_sEH, valid_dataset_sEH = splitter.train_test_split(train_dataset_sEH, frac_train=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a909a8-2c3e-473f-b55e-a9732b13f271",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffcef5d-1612-458c-aa4c-8ae9c71708a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(dataset_train, dataset_valid, save_dir):\n",
    "    model = MATModel(\n",
    "        mode='classification',\n",
    "        n_tasks=1,\n",
    "        number_of_layers=6,  # Number of Transformer layers\n",
    "        d_model=256,         # Dimensionality of model embeddings\n",
    "        num_heads=8,         # Number of attention heads\n",
    "        dropout=0.1,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Training with early stopping and learning rate scheduler\n",
    "    best_valid_score = 0\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    initial_lr = 0.001\n",
    "\n",
    "    nb_epoch = 50\n",
    "    for epoch in range(nb_epoch):\n",
    "        loss = model.fit(dataset_train, nb_epoch=1)\n",
    "        \n",
    "        # Update learning rate\n",
    "        new_lr = initial_lr * (0.9 ** (epoch // 10))  # Reduce learning rate every 10 epochs\n",
    "        model.optimizer.learning_rate = new_lr\n",
    "        \n",
    "        train_score = model.evaluate(dataset_train, [dc.metrics.roc_auc_score])\n",
    "        valid_score = model.evaluate(dataset_valid, [dc.metrics.roc_auc_score])\n",
    "        print(f\"Epoch {epoch+1}/{nb_epoch}\")\n",
    "        print(f\"  Training Loss: {loss}\")\n",
    "        print(f\"  Train ROC-AUC Score: {train_score['mean-roc_auc_score']}\")\n",
    "        print(f\"  Valid ROC-AUC Score: {valid_score['mean-roc_auc_score']}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if valid_score['mean-roc_auc_score'] > best_valid_score:\n",
    "            best_valid_score = valid_score['mean-roc_auc_score']\n",
    "            model.save_checkpoint(model_dir=save_dir)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    model.restore(model_dir=save_dir)\n",
    "    print(\"Best model restored.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1018dde-e561-42ff-9174-9ccf8b279fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sEH = train_and_evaluate(train_dataset_sEH, valid_dataset_sEH, 'mat_model_sEH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51598dc-391b-4c49-af3f-187cf79a6cc3",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f3552-8bb2-4b81-856c-f7323628c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your S3 Bucket and file key\n",
    "bucket = 'kaggle-leash-bio'\n",
    "test_parquet_key = 'test.parquet'\n",
    "test_parquet_location = f's3://{bucket}/{test_parquet_key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd7c6f-4200-433f-a7ec-3dc9052b3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Parquet file\n",
    "df = pd.read_parquet(test_parquet_location, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a6ab3-96cb-4614-ac80-7cb8866309ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for molecules binding with the sEH protein\n",
    "df_sEH_test = df[df['protein_name'] == 'sEH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73219d-e90b-4b42-a224-44b3b631ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce for quick view of the test data\n",
    "df_sEH_test = df_sEH_test.sample(frac=0.001, random_state=42)  # 20% random sample\n",
    "print(f\"New DataFrame size: {df_sEH_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea2307-a24b-4c30-b8a4-3a0590e9633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = featurizer.featurize(df_sEH_test['molecule_smiles'].tolist())\n",
    "\n",
    "# Create DeepChem dataset\n",
    "dataset = dc.data.NumpyDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90be015-2165-4f5c-9d3b-5d5b777d42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict bindings\n",
    "predictions = model.predict(dataset)\n",
    "\n",
    "# Extract the probability of the positive class (binding)\n",
    "probabilities = predictions[:, 0, 1]  # Assuming the second column corresponds to the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a75a975-b35b-44d0-8e93-e986b3a31e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resulting DataFrame with 'id' and 'binds' columns\n",
    "result_df = pd.DataFrame({\n",
    "    'id': df_sEH_test['id'],\n",
    "    'binds': probabilities\n",
    "})\n",
    "# Display the resulting DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6bd94-38f5-4014-ab10-36529c5ef483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the resulting DataFrame to a CSV file\n",
    "result_df.to_csv('MAT_sEH_predictions_50E.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
